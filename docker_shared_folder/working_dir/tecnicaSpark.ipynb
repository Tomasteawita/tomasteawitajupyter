{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347b409b-2740-4872-83ef-14a0e5e0f89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: SQLAlchemy in /opt/conda/lib/python3.11/site-packages (2.0.22)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy) (3.0.0)\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m919.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading psycopg2_binary-2.9.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m843.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: py4j, psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.9 py4j-0.10.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas requests SQLAlchemy psycopg2-binary pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dbc04e3-5d72-4575-9201-b1ff92c7ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ as env\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbdaed9-b6de-4c7f-b094-30731d080e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de configuración de Postgres\n",
    "DRIVER_PATH = env['DRIVER_PATH']\n",
    "POSTGRES_HOST = env['POSTGRES_HOST']\n",
    "POSTGRES_PORT = env['POSTGRES_PORT']\n",
    "POSTGRES_DB = env['POSTGRES_DB']\n",
    "POSTGRES_USER = env[\"POSTGRES_USER\"]\n",
    "POSTGRES_PASSWORD = env[\"POSTGRES_PASSWORD\"]\n",
    "POSTGRES_DRIVER = \"org.postgresql.Driver\"\n",
    "POSTGRES_URL = f\"jdbc:postgresql://{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd8e3d32-175f-420c-bf87-0fa6b2a7fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env['PYSPARK_SUBMIT_ARGS'] = f'--driver-class-path {DRIVER_PATH} --jars {DRIVER_PATH} pyspark-shell'\n",
    "env['SPARK_CLASSPATH'] = DRIVER_PATH\n",
    "\n",
    "# Crear sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"Spark y Postgres\") \\\n",
    "    .config(\"spark.jars\", DRIVER_PATH) \\\n",
    "    .config(\"spark.executor.extraClassPath\", DRIVER_PATH) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d309807-4139-4373-b54c-fd465f1e2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pyspark.sql import Row\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4360c002-a937-4d4e-8c9e-06c727b8934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_relevant_items_for_category(category):\n",
    "    url = f\"https://api.mercadolibre.com/sites/MLA/search?category={category}#json\"\n",
    "    response = requests.get(url).text\n",
    "    json_response = json.loads(response)\n",
    "    data = json_response[\"results\"]\n",
    "    return data\n",
    "\n",
    "def clean_string(string) -> str:\n",
    "    return str(string).replace(' ', '').strip()\n",
    "\n",
    "def load_to_postgres(spark, df, table):\n",
    "    \"\"\"\n",
    "    Carga un DataFrame de pandas en Postgres.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): El DataFrame de pandas a cargar.\n",
    "    table (str): El nombre de la tabla en Postgres donde se cargará el DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Cargar el PySpark DataFrame en Postgres\") \n",
    "    try:\n",
    "        df.write \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", POSTGRES_URL) \\\n",
    "            .option(\"dbtable\", table) \\\n",
    "            .option(\"user\", POSTGRES_USER) \\\n",
    "            .option(\"password\", POSTGRES_PASSWORD) \\\n",
    "            .option(\"driver\", POSTGRES_DRIVER) \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save()\n",
    "\n",
    "        print(\"Dataframe subido\")\n",
    "    except Exception as e:\n",
    "        print(\"Se produjo excepción:\", e)\n",
    "\n",
    "def main ():\n",
    "    CATEGORY = \"MLA1577\"\n",
    "    TABLE = \"tecnica_ml\"\n",
    "    data = get_most_relevant_items_for_category(CATEGORY)\n",
    "    DATE = str(datetime.date.today())\n",
    "    # Crear un DataFrame de Spark\n",
    "    rows = [Row(\n",
    "        id=clean_string(item['id']),\n",
    "        title=clean_string(item['title']),\n",
    "        price=float(item['price']),\n",
    "        thumbnail=clean_string(item['thumbnail']),\n",
    "        create_date=DATE) for item in data]\n",
    "    df = spark.createDataFrame(rows)\n",
    "    df.show()\n",
    "    load_to_postgres(spark, df, TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd508e3-8ae1-4af7-bd1f-d2ee6e24683e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+---------+--------------------+-----------+\n",
      "|           id|               title|    price|           thumbnail|create_date|\n",
      "+-------------+--------------------+---------+--------------------+-----------+\n",
      "|MLA1288020660|MicroondasGrillAt...| 104999.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1367525406|MicroondasBghQuic...| 139999.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1367709254|MicroondasBghEcoN...| 162349.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1134559453|MicroondasGrillAt...| 104999.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1551331924|MicroondasGrillAt...| 119999.0|http://http2.mlst...| 2023-12-10|\n",
      "| MLA932432342|MicroondasBghB120...| 135999.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1142420159|MicroondasAtmaEas...|105449.05|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1381721041|MicroondasRcaRw20...| 134062.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1498154454|MicroondasDigital...| 136099.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1137532087|MicroondasBghEcoN...| 159999.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1471987450|MicroondasGrillAt...| 128049.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1513260480|MicroondaPhilcoMp...|  91499.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1388778343|MicroondasBghQuic...| 152921.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1485882120|HornoMicroondasCo...| 277999.0|http://http2.mlst...| 2023-12-10|\n",
      "| MLA925168321|MicroondasKelvina...| 129238.2|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1124142515|MicroondasWhirlpo...| 143999.0|http://http2.mlst...| 2023-12-10|\n",
      "| MLA918105273|MicroondasBgh28Li...| 205999.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1538613938|MicroondasDigital...| 249999.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1431909284|MicroondasBghDigi...| 149999.0|http://http2.mlst...| 2023-12-10|\n",
      "|MLA1116263697|MicroondasGrillAt...| 149999.0|http://http2.mlst...| 2023-12-10|\n",
      "+-------------+--------------------+---------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Cargar el PySpark DataFrame en Postgres\n",
      "Dataframe subido\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb695fd-2dcb-49d0-80c4-9181b83fd6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb67c5-6746-486a-8c2c-1e0b5494a553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbd5b5-59c2-4848-b3e5-596782c5cce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a12d4-05e6-47f3-b892-3fdf382907d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e6bfb-d52f-4e60-bde3-68a3e17df76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188924a9-d2b4-4e16-b065-a77bd6189700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afcda2-8f78-4ffe-85bb-d66848bc9760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
